# Nikisep
Niki akhavanniaki, Sepehr Abdi Goudarzi
Title of chosen project: Split Computing and Early Exiting for Deep Learning
Applications: Survey and Research Challenges
Introduction:
Recently, split computing (SC)-based approaches have been put out, where the DNN is divided into a head and a tail model, which are then processed on the edge server and the mobile device, respectively. In the end, this might both bandwidth and energy use are involved. Models are trained using a different strategy termed early exiting (EE). To incorporate several "exits" earlier in the architecture, each of which offers progressively had better target precision. Consequently, the trade-off between accuracy and latency can be adjusted based on the circumstances or an application requires.

Our Study:
We prove a re-implementation on of the benchmarks of this paper which it is early exits. So we provide two models which one of them is without early exits and one of them with 2 early on CIFAR-10 dataset which can predict the lable of the pictures. 
